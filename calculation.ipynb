{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You can find the source for `wmfdata` at https://github.com/neilpquinn/wmfdata\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "import re\n",
    "import io\n",
    "from functools import reduce\n",
    "\n",
    "import pandas as pd\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "import wmfdata as wmf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TSV file where metrics are or will be saved\n",
    "FILENAME = \"metrics/metrics.tsv\"\n",
    "\n",
    "# Latest mediawiki_history snapshot in Hive\n",
    "SNAPSHOT = \"2018-07\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading previous results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-01\n"
     ]
    }
   ],
   "source": [
    "# What about preserving partially complete rows?\n",
    "\n",
    "try:\n",
    "    old_metrics = pd.read_csv(FILENAME, sep=\"\\t\", parse_dates = [\"month\"])\n",
    "    START = old_metrics[\"month\"].max() + relativedelta(months=1)\n",
    "except FileNotFoundError:\n",
    "    START = pd.Timestamp(2001, 1, 1)\n",
    "    old_metrics = None\n",
    "\n",
    "START = START.strftime(\"%Y-%m-%d\")\n",
    "print(START)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single-query metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdb_queries = {\n",
    "    \n",
    "    # To-do: active editors with null registration aren't classified as existing (?)\n",
    "    \"active_editors\": {\n",
    "        \"file\": \"queries/active_editors.sql\"\n",
    "    },\n",
    "    \"edits\": {\n",
    "        \"file\": \"queries/mobile_edits.sql\",\n",
    "    }\n",
    "}\n",
    "\n",
    "hive_queries = {\n",
    "    \"edits\": {\n",
    "        \"file\": \"queries/edits.hql\",\n",
    "    },\n",
    "    \"new_editor_retention\": {\n",
    "        \"file\": \"queries/new_editor_retention.hql\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running active_editors...\n",
      "Running edits...\n"
     ]
    }
   ],
   "source": [
    "for k in mdb_queries:\n",
    "    q = mdb_queries[k]\n",
    "    with open(q[\"file\"]) as f:\n",
    "        text = f.read()\n",
    "        \n",
    "    wmf.utils.print_err(\"Running {}...\".format(k))\n",
    "    q[\"result\"] = wmf.mariadb.run(text.format(start = START))\n",
    "    q[\"result\"][\"month\"] = pd.to_datetime(q[\"result\"][\"month\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running new_editor_retention...\n",
      "Running edits...\n"
     ]
    }
   ],
   "source": [
    "for k in hive_queries:\n",
    "    q = hive_queries[k]\n",
    "    with open(q[\"file\"]) as f:\n",
    "        text = f.read()\n",
    "        \n",
    "    wmf.utils.print_err(\"Running {}...\".format(k))\n",
    "    q[\"result\"] = wmf.hive.run(text.format(start = START, snapshot = SNAPSHOT))\n",
    "    # Unlike our MariaDB queries, the Hive query returns a string rather than a date\n",
    "    q[\"result\"][\"month\"] = pd.to_datetime(q[\"result\"][\"month\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiquery metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull Wikistats data files, removing old copies from previous runs\n",
    "wikistats_files = \"csv_*_main.zip\"\n",
    "wikistats_path = \"/mnt/data/xmldatadumps/public/other/wikistats_1/\"\n",
    "!rm data/{wikistats_files}\n",
    "!cp {wikistats_path}{wikistats_files} data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wiki</th>\n",
       "      <th>group</th>\n",
       "      <th>month</th>\n",
       "      <th>articles</th>\n",
       "      <th>files</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1918</th>\n",
       "      <td>wikidata</td>\n",
       "      <td>wx</td>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>47806432</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1919</th>\n",
       "      <td>wikidata</td>\n",
       "      <td>wx</td>\n",
       "      <td>2018-04-30</td>\n",
       "      <td>48954239</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1920</th>\n",
       "      <td>wikidata</td>\n",
       "      <td>wx</td>\n",
       "      <td>2018-05-31</td>\n",
       "      <td>50429005</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1921</th>\n",
       "      <td>wikidata</td>\n",
       "      <td>wx</td>\n",
       "      <td>2018-06-30</td>\n",
       "      <td>51015817</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1922</th>\n",
       "      <td>wikidata</td>\n",
       "      <td>wx</td>\n",
       "      <td>2018-07-31</td>\n",
       "      <td>51484822</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          wiki group      month  articles  files\n",
       "1918  wikidata    wx 2018-03-31  47806432    0.0\n",
       "1919  wikidata    wx 2018-04-30  48954239    0.0\n",
       "1920  wikidata    wx 2018-05-31  50429005    0.0\n",
       "1921  wikidata    wx 2018-06-30  51015817    0.0\n",
       "1922  wikidata    wx 2018-07-31  51484822    0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zipfiles = !ls data/csv_*_main.zip\n",
    "cols = [\"wiki\", \"group\", \"month\", \"articles\", \"files\"]\n",
    "content = pd.DataFrame(columns=cols)\n",
    "\n",
    "for f in zipfiles:\n",
    "    # Extract the Wikistats code for the project family\n",
    "    grp = re.search(r\"data/csv_([a-z]{2})_main.zip\", f).group(1)\n",
    "    \n",
    "    # Map Wikistats codes for project family to the corresponding database codes\n",
    "    db_suffix = {\n",
    "        \"wb\": \"wikibooks\",\n",
    "        \"wk\": \"wiktionary\",\n",
    "        \"wn\": \"wikinews\",\n",
    "        \"wo\": \"wikivoyage\",\n",
    "        \"wp\": \"wiki\",\n",
    "        \"wq\": \"wikiquote\",\n",
    "        \"ws\": \"wikisource\",\n",
    "        \"wv\": \"wikiversity\",\n",
    "        \"wx\": \"\"\n",
    "    }\n",
    "    \n",
    "    # Unzip files to stdout and capture it in an IPython SList.\n",
    "    # Put the newline-separated string (`.n`) of the output in a buffer for Pandas.\n",
    "    sm = !unzip -p {f} StatisticsMonthly.csv\n",
    "    sm = io.StringIO(sm.n)\n",
    "    \n",
    "    spn = !unzip -p {f} StatisticsPerNamespace.csv\n",
    "    spn = io.StringIO(spn.n)\n",
    "     \n",
    "    # Manually set column numbers because some CSVs are ragged \n",
    "    # Select the columns we need, which aren't named so we need to select by location\n",
    "    art = pd.read_csv(sm, header=None, usecols=[0, 1, 6], names=range(29))\n",
    "    art.columns = [\"wiki\", \"month\", \"articles\"]\n",
    "\n",
    "    # Wikisource has extra namespaces so its file has more columns\n",
    "    if grp == \"ws\":\n",
    "        col_nums = range(22)\n",
    "    else:\n",
    "        col_nums = range(17)\n",
    "    \n",
    "    files = pd.read_csv(spn, header=None, usecols=[0, 1, 5], names=col_nums)\n",
    "    files.columns = [\"wiki\", \"month\", \"files\"]\n",
    "        \n",
    "    grp_content = pd.merge(art, files, on=[\"wiki\", \"month\"], validate=\"one_to_one\")\n",
    "        \n",
    "    # Wiki column just contains the language code (except in wx) so we have to disambiguate across files\n",
    "    grp_content[\"wiki\"] = grp_content[\"wiki\"] + db_suffix[grp]\n",
    "    \n",
    "    grp_content[\"group\"] = grp\n",
    "    \n",
    "    content = content.append(grp_content, sort=False)\n",
    "    \n",
    "    sm.close()\n",
    "    spn.close()\n",
    "\n",
    "content[\"month\"] = pd.to_datetime(content[\"month\"])\n",
    "content[\"articles\"] = content[\"articles\"].astype(int)\n",
    "\n",
    "# Remove \"wikis\" with zz codes since those are aggregates\n",
    "not_zz = lambda df: ~df[\"wiki\"].str.match(r\"zz.*\")\n",
    "content = content[not_zz]\n",
    "\n",
    "content.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_content</th>\n",
       "      <th>wikipedia_articles</th>\n",
       "      <th>files</th>\n",
       "      <th>wikidata_entities</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-03-31</th>\n",
       "      <td>185953773.0</td>\n",
       "      <td>47673077.0</td>\n",
       "      <td>49609426.0</td>\n",
       "      <td>47806432.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-30</th>\n",
       "      <td>188148690.0</td>\n",
       "      <td>47845039.0</td>\n",
       "      <td>50236865.0</td>\n",
       "      <td>48954239.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-31</th>\n",
       "      <td>191319173.0</td>\n",
       "      <td>48018756.0</td>\n",
       "      <td>50974289.0</td>\n",
       "      <td>50429005.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-30</th>\n",
       "      <td>192994298.0</td>\n",
       "      <td>48185189.0</td>\n",
       "      <td>51583644.0</td>\n",
       "      <td>51015817.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-31</th>\n",
       "      <td>194863953.0</td>\n",
       "      <td>48404160.0</td>\n",
       "      <td>52265767.0</td>\n",
       "      <td>51484822.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            total_content  wikipedia_articles       files  wikidata_entities\n",
       "month                                                                       \n",
       "2018-03-31    185953773.0          47673077.0  49609426.0         47806432.0\n",
       "2018-04-30    188148690.0          47845039.0  50236865.0         48954239.0\n",
       "2018-05-31    191319173.0          48018756.0  50974289.0         50429005.0\n",
       "2018-06-30    192994298.0          48185189.0  51583644.0         51015817.0\n",
       "2018-07-31    194863953.0          48404160.0  52265767.0         51484822.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Content is articles + files on all wikis except Commons, \n",
    "# where it's files alone since there files count as articles\n",
    "def count_content(df):\n",
    "    files = df[\"files\"].sum()\n",
    "    noncommons_articles = df[df[\"wiki\"] != \"commons\"][\"articles\"].sum()\n",
    "    total_content = noncommons_articles + files\n",
    "    wikipedia_articles = df[df[\"group\"] == \"wp\"][\"articles\"].sum()\n",
    "    wikidata_entities = df[df[\"wiki\"] == \"wikidata\"][\"articles\"].sum()\n",
    "\n",
    "    return pd.Series(\n",
    "        [total_content, wikipedia_articles, files, wikidata_entities],\n",
    "        index=[\"total_content\", \"wikipedia_articles\", \"files\", \"wikidata_entities\"]\n",
    "    )\n",
    "\n",
    "glob_cont = content.groupby(\"month\").apply(count_content)\n",
    "glob_cont.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>total_content</th>\n",
       "      <th>wikipedia_articles</th>\n",
       "      <th>files</th>\n",
       "      <th>wikidata_entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-05-01</td>\n",
       "      <td>191319173.0</td>\n",
       "      <td>48018756.0</td>\n",
       "      <td>50974289.0</td>\n",
       "      <td>50429005.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-06-01</td>\n",
       "      <td>192994298.0</td>\n",
       "      <td>48185189.0</td>\n",
       "      <td>51583644.0</td>\n",
       "      <td>51015817.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-07-01</td>\n",
       "      <td>194863953.0</td>\n",
       "      <td>48404160.0</td>\n",
       "      <td>52265767.0</td>\n",
       "      <td>51484822.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       month  total_content  wikipedia_articles       files  wikidata_entities\n",
       "0 2018-05-01    191319173.0          48018756.0  50974289.0         50429005.0\n",
       "1 2018-06-01    192994298.0          48185189.0  51583644.0         51015817.0\n",
       "2 2018-07-01    194863953.0          48404160.0  52265767.0         51484822.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove dates with 0 articles, because those are junk data\n",
    "glob_cont = glob_cont[glob_cont[\"wikipedia_articles\"] != 0]\n",
    "\n",
    "# This data is calculated as of the end of a calendar month. In other places,\n",
    "# the metric is dated the first day of that month it applies to. Let's convert\n",
    "# to that.\n",
    "glob_cont.index = glob_cont.index - pd.tseries.offsets.MonthBegin()\n",
    "\n",
    "glob_cont = glob_cont[START:]\n",
    "\n",
    "# Reset index so we can merge\n",
    "glob_cont = glob_cont.reset_index()\n",
    "\n",
    "glob_cont.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining and saving metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>active_editors</th>\n",
       "      <th>existing_active_editors</th>\n",
       "      <th>new_active_editors</th>\n",
       "      <th>second_month_active_editors</th>\n",
       "      <th>mobile_edits</th>\n",
       "      <th>new_editor_retention</th>\n",
       "      <th>total_edits</th>\n",
       "      <th>uploads</th>\n",
       "      <th>data_edits</th>\n",
       "      <th>nonbot_nondata_nonupload_edits</th>\n",
       "      <th>revert_rate</th>\n",
       "      <th>total_content</th>\n",
       "      <th>wikipedia_articles</th>\n",
       "      <th>files</th>\n",
       "      <th>wikidata_entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>2018-03-01</td>\n",
       "      <td>86190</td>\n",
       "      <td>63332.0</td>\n",
       "      <td>17625.0</td>\n",
       "      <td>4347.0</td>\n",
       "      <td>1121184.0</td>\n",
       "      <td>0.064066</td>\n",
       "      <td>43033263</td>\n",
       "      <td>806356</td>\n",
       "      <td>17995388</td>\n",
       "      <td>14685039</td>\n",
       "      <td>0.071150</td>\n",
       "      <td>185993282.0</td>\n",
       "      <td>47686797.0</td>\n",
       "      <td>49632489.0</td>\n",
       "      <td>47812006.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>2018-04-01</td>\n",
       "      <td>83705</td>\n",
       "      <td>62042.0</td>\n",
       "      <td>16059.0</td>\n",
       "      <td>4739.0</td>\n",
       "      <td>1107284.0</td>\n",
       "      <td>0.057341</td>\n",
       "      <td>34541104</td>\n",
       "      <td>628380</td>\n",
       "      <td>12847031</td>\n",
       "      <td>13760495</td>\n",
       "      <td>0.082339</td>\n",
       "      <td>188191961.0</td>\n",
       "      <td>47859087.0</td>\n",
       "      <td>50263125.0</td>\n",
       "      <td>48959861.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>2018-05-01</td>\n",
       "      <td>85424</td>\n",
       "      <td>62698.0</td>\n",
       "      <td>17787.0</td>\n",
       "      <td>4068.0</td>\n",
       "      <td>1165558.0</td>\n",
       "      <td>0.047123</td>\n",
       "      <td>39081127</td>\n",
       "      <td>735020</td>\n",
       "      <td>15706189</td>\n",
       "      <td>14355475</td>\n",
       "      <td>0.076782</td>\n",
       "      <td>191319173.0</td>\n",
       "      <td>48018756.0</td>\n",
       "      <td>50974289.0</td>\n",
       "      <td>50429005.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>2018-06-01</td>\n",
       "      <td>78549</td>\n",
       "      <td>59034.0</td>\n",
       "      <td>15005.0</td>\n",
       "      <td>3664.0</td>\n",
       "      <td>1128001.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37113955</td>\n",
       "      <td>608120</td>\n",
       "      <td>16475423</td>\n",
       "      <td>12996694</td>\n",
       "      <td>0.073959</td>\n",
       "      <td>192994298.0</td>\n",
       "      <td>48185189.0</td>\n",
       "      <td>51583644.0</td>\n",
       "      <td>51015817.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>2018-07-01</td>\n",
       "      <td>77734</td>\n",
       "      <td>59386.0</td>\n",
       "      <td>14037.0</td>\n",
       "      <td>3455.0</td>\n",
       "      <td>1169233.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36940332</td>\n",
       "      <td>675219</td>\n",
       "      <td>14131553</td>\n",
       "      <td>13391867</td>\n",
       "      <td>0.067250</td>\n",
       "      <td>194863953.0</td>\n",
       "      <td>48404160.0</td>\n",
       "      <td>52265767.0</td>\n",
       "      <td>51484822.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         month  active_editors  existing_active_editors  new_active_editors  \\\n",
       "207 2018-03-01           86190                  63332.0             17625.0   \n",
       "208 2018-04-01           83705                  62042.0             16059.0   \n",
       "209 2018-05-01           85424                  62698.0             17787.0   \n",
       "210 2018-06-01           78549                  59034.0             15005.0   \n",
       "211 2018-07-01           77734                  59386.0             14037.0   \n",
       "\n",
       "     second_month_active_editors  mobile_edits  new_editor_retention  \\\n",
       "207                       4347.0     1121184.0              0.064066   \n",
       "208                       4739.0     1107284.0              0.057341   \n",
       "209                       4068.0     1165558.0              0.047123   \n",
       "210                       3664.0     1128001.0                   NaN   \n",
       "211                       3455.0     1169233.0                   NaN   \n",
       "\n",
       "     total_edits  uploads  data_edits  nonbot_nondata_nonupload_edits  \\\n",
       "207     43033263   806356    17995388                        14685039   \n",
       "208     34541104   628380    12847031                        13760495   \n",
       "209     39081127   735020    15706189                        14355475   \n",
       "210     37113955   608120    16475423                        12996694   \n",
       "211     36940332   675219    14131553                        13391867   \n",
       "\n",
       "     revert_rate  total_content  wikipedia_articles       files  \\\n",
       "207     0.071150    185993282.0          47686797.0  49632489.0   \n",
       "208     0.082339    188191961.0          47859087.0  50263125.0   \n",
       "209     0.076782    191319173.0          48018756.0  50974289.0   \n",
       "210     0.073959    192994298.0          48185189.0  51583644.0   \n",
       "211     0.067250    194863953.0          48404160.0  52265767.0   \n",
       "\n",
       "     wikidata_entities  \n",
       "207         47812006.0  \n",
       "208         48959861.0  \n",
       "209         50429005.0  \n",
       "210         51015817.0  \n",
       "211         51484822.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = [mdb_queries[k][\"result\"] for k in mdb_queries]\n",
    "dfs.extend([hive_queries[k][\"result\"] for k in hive_queries])\n",
    "dfs.append(glob_cont)\n",
    "new_metrics = reduce(lambda l, r: pd.merge(l, r, how=\"outer\"), dfs)\n",
    "\n",
    "if old_metrics is not None:\n",
    "    metrics = pd.concat([old_metrics, new_metrics], sort=False)\n",
    "else:\n",
    "    metrics = new_metrics\n",
    "\n",
    "metrics = metrics.reset_index(drop=True)\n",
    "metrics.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.to_csv(FILENAME, sep=\"\\t\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
